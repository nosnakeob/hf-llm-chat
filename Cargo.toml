[package]
name = "hf-llm-chat"
version = "0.2.0"
edition = "2024"

[lints.rust]
unused = "allow"

[dependencies]
anyhow = "1"
tokio = { version = "1", features = ["full"] }
# intel-mkl-src = { version = "0.8", features = ["mkl-static-lp64-iomp"] }

candle = { package = "candle-core", version = "0.9", features = ["cuda"] }
candle-transformers = { version = "0.9", features = ["cuda"] }
candle-examples = "0.9"

hf-hub = { version = "0.4", features = ["tokio"] }
tokenizers = "0.21"

async-stream = "0.3"
futures-core = "0.3"
futures-util = "0.3"

tracing = "0.1"
tracing-subscriber = "0.3"

which = "7"

config = "0.15"
hf-chat-template = { version = "0.3", git = "https://github.com/nosnakeob/hf-chat-template.git" }
