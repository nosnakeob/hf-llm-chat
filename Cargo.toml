[package]
name = "candle-llm-chat"
version = "0.5.1"
edition = "2024"

[lints.rust]
unused = "allow"

[dependencies]
anyhow = "1.0"
tokio = "1.48"
# intel-mkl-src = { version = "0.8", features = ["mkl-static-lp64-iomp"] }

candle = { package = "candle-core", version = "0.9.2-alpha.1" }
candle-nn = "0.9.2-alpha.1"
# feat mkl STATUS_DLL_NOT_FOUND
candle-transformers = { version = "0.9.2-alpha.1", features = [
    "cuda",
    "cudnn",
    # "flash-attn",
] }
candle-examples = "0.9.2-alpha.1"

hf-hub = { version = "0.4", features = ["tokio"] }
tokenizers = "0.21"

async-stream = "0.3"
futures-core = "0.3"
futures-util = "0.3"

tracing = "0.1"

which = "8.0"

config = "0.15"
serde_json = "1.0"
serde = { version = "1.0", features = ["derive"] }
derive-new = "0.7"
strum = { version = "0.27", features = ["derive"] }
minijinja = { version = "2.12", features = ["loader"] }
minijinja-contrib = { version = "2.12", features = ["pycompat"] }

[dev-dependencies]
tracing-subscriber = "0.3"
